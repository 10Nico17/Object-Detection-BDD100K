{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mdwsYPdh5yvV",
        "outputId": "90c676e3-dcce-460b-c49a-beccf245442e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install comet_ml --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR1BTbaGYEFF",
        "outputId": "e9d4a76d-8bfa-4bf7-ffd9-080490eef843"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.1/645.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.7/514.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml\n",
        "comet_ml.init(project_name='comet-nico-yolov8')"
      ],
      "metadata": {
        "id": "O7d24bZnYF2U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "uYWBgl82yaNM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LicensePlate.zip\"\n"
      ],
      "metadata": {
        "id": "ghcuNOgW541u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/bdd100knewsmall.zip\""
      ],
      "metadata": {
        "id": "BAKLL6SKZN3Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg_DjTGxBH6j",
        "outputId": "60516009-c240-4180-a5b9-262d38b435e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 11 13:45:33 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "rlzGV3Tt544A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 3. Install Ultralytics ###\n",
        "\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "FHNYN3Tg546X",
        "outputId": "08e8f0a5-ce22-4489-fd4a-948cd3192d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.46-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.4/750.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Train model ###\n",
        "\n",
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8m.pt\")  # load pre trained model\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(ROOT_DIR, \"dataset_bdd100k.yaml\"), epochs=20)  # train the model"
      ],
      "metadata": {
        "id": "IzWQAXb4548o",
        "outputId": "f8819083-bc38-42a2-e281-f4bfa00c0819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 61.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.46 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/MyDrive/dataset_bdd100k.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 4.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3780328  ultralytics.nn.modules.head.Detect           [8, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25860952 parameters, 25860936 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/nico10hahn/comet-nico-yolov8/c5310fde001a4cca9ca470539c8c4aff\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 23.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/bdd100knewsmall/labels/train... 21000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 21000/21000 [00:16<00:00, 1251.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/bdd100knewsmall/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/bdd100knewsmall/labels/test... 4500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4500/4500 [00:04<00:00, 1118.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bdd100knewsmall/labels/test.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      8.68G      1.281     0.9586      1.014        178        640: 100%|██████████| 1313/1313 [04:41<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:26<00:00,  5.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.562      0.425      0.443      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      8.82G      1.299     0.8605      1.025        192        640: 100%|██████████| 1313/1313 [04:21<00:00,  5.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.587      0.425      0.441      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      8.54G      1.286     0.8409      1.021        211        640: 100%|██████████| 1313/1313 [04:17<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.603      0.429      0.462      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20      8.76G      1.263     0.8077       1.01        284        640: 100%|██████████| 1313/1313 [04:14<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.614       0.45      0.487      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      9.83G      1.238     0.7783     0.9998        258        640: 100%|██████████| 1313/1313 [04:14<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.611      0.481      0.506       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20      9.25G      1.221     0.7552      0.994        287        640: 100%|██████████| 1313/1313 [04:14<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.607      0.481      0.513      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20      9.11G      1.205     0.7408     0.9869        233        640: 100%|██████████| 1313/1313 [04:14<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.651      0.488      0.537       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20      9.74G      1.194     0.7254     0.9822        202        640: 100%|██████████| 1313/1313 [04:13<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.649      0.498      0.543      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      9.63G      1.181     0.7121     0.9774        210        640: 100%|██████████| 1313/1313 [04:14<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.661      0.496      0.545      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20      10.2G      1.174     0.7026     0.9736        185        640: 100%|██████████| 1313/1313 [04:14<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.661      0.511       0.56      0.327\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20      9.14G      1.209     0.7059     0.9776        154        640: 100%|██████████| 1313/1313 [04:16<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.674      0.501      0.556      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20       9.2G      1.201     0.6944     0.9756        155        640: 100%|██████████| 1313/1313 [04:09<00:00,  5.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.688      0.507      0.562      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      9.36G      1.193     0.6854     0.9727        122        640: 100%|██████████| 1313/1313 [04:09<00:00,  5.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.674      0.519       0.57      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      9.37G      1.184     0.6735     0.9678        127        640: 100%|██████████| 1313/1313 [04:09<00:00,  5.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.662      0.522      0.568      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20      9.72G      1.176     0.6631     0.9638         83        640: 100%|██████████| 1313/1313 [04:08<00:00,  5.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.675      0.536      0.577      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20      9.84G      1.169     0.6546     0.9609        129        640: 100%|██████████| 1313/1313 [04:08<00:00,  5.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680       0.67      0.536      0.584      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20        10G       1.16     0.6423     0.9587        152        640: 100%|██████████| 1313/1313 [04:08<00:00,  5.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.687      0.533      0.586      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      10.2G      1.149     0.6315     0.9535        118        640: 100%|██████████| 1313/1313 [04:08<00:00,  5.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.697      0.536      0.589      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      10.3G      1.142     0.6208      0.951        173        640: 100%|██████████| 1313/1313 [04:08<00:00,  5.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.699      0.535      0.591      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      10.5G      1.134     0.6115     0.9463        100        640: 100%|██████████| 1313/1313 [04:09<00:00,  5.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.697      0.541      0.595      0.356\n",
            "\n",
            "20 epochs completed in 1.565 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.46 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "Model summary (fused): 218 layers, 25844392 parameters, 0 gradients, 78.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 141/141 [00:46<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4500      81680      0.698      0.541      0.595      0.355\n",
            "                   car       4500      45560        0.8      0.712      0.782      0.507\n",
            "            pedestrian       4500       6082      0.732      0.527      0.607      0.307\n",
            "                 rider       4500        278      0.653      0.393      0.422      0.227\n",
            "                 truck       4500       1669      0.608       0.55      0.564      0.415\n",
            "                   bus       4500        784      0.674      0.551      0.611      0.475\n",
            "         traffic light       4500      12267      0.701      0.491      0.546      0.212\n",
            "          traffic sign       4500      15040      0.716      0.563      0.631      0.343\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : faint_drip_5734\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/nico10hahn/comet-nico-yolov8/c5310fde001a4cca9ca470539c8c4aff\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [2627]               : (21.45658302307129, 106.44322967529297)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [41]               : (4.9563500000000035e-05, 0.0007503424610307185)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [41]               : (4.9563500000000035e-05, 0.0007503424610307185)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [41]               : (4.9563500000000035e-05, 0.0007503424610307185)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [42]     : (0.44053, 0.5947397871010734)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [42]  : (0.244, 0.35552)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [42] : (0.56203, 0.69907)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [42]    : (0.4246, 0.5410916853768967)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 79.088\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 25860952\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 1.774\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [40]       : (1.13357, 1.29947)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [40]       : (0.61146, 0.95861)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [40]       : (0.94625, 1.02461)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [40]         : (1.14968, 1.30493)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [40]         : (0.62911, 0.83076)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [40]         : (0.95509, 1.0206)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /content/drive/MyDrive/dataset_bdd100k.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 20\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8m.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (49.60 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 21.37 MB/49.60 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_y7z9qCLrrA",
        "outputId": "3b6aef59-b8f0-4b78-f022-e44f17d73048"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 295 layers, 25860952 parameters, 0 gradients, 79.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(295, 25860952, 0, 79.0881792)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UqTK2G3Lugg",
        "outputId": "6b054e0d-f64d-42c5-b023-27d419837020"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO(\n",
            "  (model): DetectionModel(\n",
            "    (model): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Conv(\n",
            "        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (4): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-3): 4 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Conv(\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (6): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-3): 4 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (7): Conv(\n",
            "        (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (8): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): SPPF(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): Concat()\n",
            "      (12): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (14): Concat()\n",
            "      (15): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (16): Conv(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (17): Concat()\n",
            "      (18): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (19): Conv(\n",
            "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (20): Concat()\n",
            "      (21): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (22): Detect(\n",
            "        (cv2): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (cv3): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (dfl): DFL(\n",
            "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference Time**"
      ],
      "metadata": {
        "id": "XdD7aN7gQZn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model('/content/bdd100knewsmall/images/test/00067cfb-5443fe39.jpg')\n"
      ],
      "metadata": {
        "id": "La0CUtxE55Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6a0088-bb06-41c8-976d-9bd5f68edc7b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/00067cfb-5443fe39.jpg: 384x640 14 cars, 2 pedestrians, 2 traffic signs, 150.4ms\n",
            "Speed: 1.7ms preprocess, 150.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict some Random Images**"
      ],
      "metadata": {
        "id": "Iu6z2YpySSOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "i1CWPyCFQcty"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Verzeichnis mit Bildern\n",
        "images_dir = '/content/bdd100knewsmall/images/test/'\n",
        "\n",
        "# Liste der Dateien im Verzeichnis\n",
        "image_files = os.listdir(images_dir)\n",
        "\n",
        "# Zufällige Auswahl von fünf Bildern\n",
        "random_images = random.sample(image_files, 5)\n",
        "\n",
        "# Für jedes ausgewählte Bild\n",
        "for image_file in random_images:\n",
        "    # Pfad zum Bild\n",
        "    image_path = os.path.join(images_dir, image_file)\n",
        "\n",
        "    # Laden des Bildes\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Vorhersage mit dem Modell\n",
        "    results = model(image_path,save=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnb4HeQQQuUr",
        "outputId": "82c2b635-97c7-4b51-a6c4-52538e6aa535"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/4c7c4eb3-45253918.jpg: 384x640 7 cars, 1 pedestrian, 5 traffic lights, 3 traffic signs, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/5ea1f2ff-b711934b.jpg: 384x640 13 cars, 1 pedestrian, 1 traffic sign, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/02a46296-f95ec53f.jpg: 384x640 5 cars, 1 pedestrian, 5 traffic lights, 2 traffic signs, 11.3ms\n",
            "Speed: 1.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/6adb1b8c-ea1e8e8d.jpg: 384x640 3 cars, 2 traffic lights, 1 traffic sign, 11.7ms\n",
            "Speed: 1.6ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/70aee1aa-2792525a.jpg: 384x640 14 cars, 2 pedestrians, 4 traffic lights, 3 traffic signs, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train on second dataset**"
      ],
      "metadata": {
        "id": "VxaLQN-xVawq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on LicensePlate dataset"
      ],
      "metadata": {
        "id": "poAWGZX1rrt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Train model ###\n",
        "\n",
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model2 = YOLO(\"/content/runs/detect/train/weights/best.pt\")  # load pre trained model\n",
        "\n",
        "# Use the model\n",
        "results = model2.train(data=os.path.join(ROOT_DIR, \"dataset_LicensePlate.yaml\"), epochs=10)  # train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUXkgbAPryOT",
        "outputId": "2fcf157d-c280-40cd-dc51-7fc2facf80e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.46 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/runs/detect/train/weights/best.pt, data=/content/drive/MyDrive/dataset_LicensePlate.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3780328  ultralytics.nn.modules.head.Detect           [8, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25860952 parameters, 25860936 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 475/475 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/nico10hahn/comet-nico-yolov8/b0385c8f43cf41a99601bfb9ee161e9f\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/LicensePlate/labels/train... 245 images, 0 backgrounds, 0 corrupt: 100%|██████████| 245/245 [00:00<00:00, 1147.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/LicensePlate/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/LicensePlate/labels/val... 70 images, 0 backgrounds, 0 corrupt: 100%|██████████| 70/70 [00:00<00:00, 1066.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/LicensePlate/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train7/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train7\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      11.7G      1.424      3.451      1.903         23        640: 100%|██████████| 16/16 [00:05<00:00,  3.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.375      0.354      0.379      0.254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10        12G      1.231      2.318      1.779         13        640: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.801      0.304      0.502      0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      12.3G      1.111      1.979      1.575         11        640: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.879      0.358      0.555      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      12.5G     0.9912      1.414      1.455         15        640: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.651      0.722      0.705      0.493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      12.6G     0.9129      1.012       1.38          9        640: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.769      0.722       0.77      0.553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      12.8G     0.8383     0.8401      1.294         10        640: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.805      0.758      0.803      0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      12.9G     0.8477     0.8405      1.281         25        640: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218       0.82      0.765      0.811      0.616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      13.1G     0.8309     0.7864      1.281         12        640: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.851      0.751      0.825       0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      13.3G     0.7909     0.7268      1.233         15        640: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.838      0.757      0.824      0.633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      13.4G     0.7782     0.7398      1.237         21        640: 100%|██████████| 16/16 [00:03<00:00,  5.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.832      0.758      0.823      0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from runs/detect/train7/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train7/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train7/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.46 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "Model summary (fused): 218 layers, 25844392 parameters, 0 gradients, 78.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         70        218      0.835      0.761      0.824      0.634\n",
            "         license-plate         70         84      0.861      0.738      0.804      0.606\n",
            "                   car         70        134       0.81      0.784      0.844      0.661\n",
            "Speed: 0.2ms preprocess, 2.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train7\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : sleepy_opossum_7103\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/nico10hahn/comet-nico-yolov8/b0385c8f43cf41a99601bfb9ee161e9f\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [17]                 : (17.734424591064453, 127.68585205078125)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [21]               : (9.079699999999998e-05, 0.00039963175)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [21]               : (9.079699999999998e-05, 0.00039963175)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [21]               : (9.079699999999998e-05, 0.00039963175)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [22]     : (0.37929, 0.82529)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [22]  : (0.25391, 0.6337305658825576)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [22] : (0.3748, 0.87872)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [22]    : (0.30405, 0.76537)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 79.088\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 25860952\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 7.993\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [20]       : (0.77819, 1.42364)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [20]       : (0.72678, 3.45135)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [20]       : (1.23275, 1.90336)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [20]         : (0.92378, 1.41545)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [20]         : (0.83077, 2.49519)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [20]         : (1.37149, 2.2217)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /content/drive/MyDrive/dataset_LicensePlate.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : /content/runs/detect/train/weights/best.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (49.63 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 151 metrics, params and output messages\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 17.02 MB/49.63 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verzeichnis mit Bildern\n",
        "images_dir = '/content/LicensePlate/images/test/'\n",
        "\n",
        "# Liste der Dateien im Verzeichnis\n",
        "image_files = os.listdir(images_dir)\n",
        "\n",
        "# Zufällige Auswahl von fünf Bildern\n",
        "random_images = random.sample(image_files, 5)\n",
        "\n",
        "# Für jedes ausgewählte Bild\n",
        "for image_file in random_images:\n",
        "    # Pfad zum Bild\n",
        "    image_path = os.path.join(images_dir, image_file)\n",
        "\n",
        "    # Laden des Bildes\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Vorhersage mit dem Modell\n",
        "    results = model2(image_path,save=True)"
      ],
      "metadata": {
        "id": "DHNYik09ryQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc6048c-f6fe-449c-ab2c-492834a2a67f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/LicensePlate/images/test/be9fd0014b5a4f2a_jpg.rf.20dc7369d0a83ad74a123727228dce11.jpg: 640x640 1 license-plate, 1 car, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train712\u001b[0m\n",
            "\n",
            "image 1/1 /content/LicensePlate/images/test/c1d8b110186e095a_jpg.rf.1515701021c709417f9e92537a1d3714.jpg: 640x640 1 license-plate, 4 cars, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train713\u001b[0m\n",
            "\n",
            "image 1/1 /content/LicensePlate/images/test/bd12ea92bcab1afd_jpg.rf.fe51aa4c3da615ae6656ea88fc7250e3.jpg: 640x640 6 cars, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train714\u001b[0m\n",
            "\n",
            "image 1/1 /content/LicensePlate/images/test/b94993a2d67b455e_jpg.rf.62712d980344cb842644f82e63b13092.jpg: 640x640 1 license-plate, 2 cars, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train715\u001b[0m\n",
            "\n",
            "image 1/1 /content/LicensePlate/images/test/d2fe2b47668e9d8e_jpg.rf.c3c019d146ec1fc0bcf7fbeb12c7bc7f.jpg: 640x640 1 license-plate, 1 car, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train716\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verzeichnis mit Bildern\n",
        "images_dir = '/content/bdd100knewsmall/images/test/'\n",
        "\n",
        "# Liste der Dateien im Verzeichnis\n",
        "image_files = os.listdir(images_dir)\n",
        "\n",
        "# Zufällige Auswahl von fünf Bildern\n",
        "random_images = random.sample(image_files, 10)\n",
        "\n",
        "# Für jedes ausgewählte Bild\n",
        "for image_file in random_images:\n",
        "    # Pfad zum Bild\n",
        "    image_path = os.path.join(images_dir, image_file)\n",
        "\n",
        "    # Laden des Bildes\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Vorhersage mit dem Modell\n",
        "    results = model2(image_path,save=True)"
      ],
      "metadata": {
        "id": "gCtou5cqryS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054512b5-0a24-4d7f-f907-216501fbaa31"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/27764b50-4df2e277.jpg: 384x640 5 cars, 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train72\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/66bf95f9-d8d18d04.jpg: 384x640 2 license-plates, 6 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train73\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/10a103b3-3a42fe0a.jpg: 384x640 4 cars, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train74\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/661e9976-788d0b85.jpg: 384x640 13 cars, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train75\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/760e39d9-abd0917b.jpg: 384x640 5 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train76\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/616411ef-87a1fdaf.jpg: 384x640 8 cars, 16.0ms\n",
            "Speed: 1.8ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train77\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/38221668-69780e2f.jpg: 384x640 2 cars, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train78\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/4fba20ab-342281d6.jpg: 384x640 3 cars, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train79\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/96d11b79-74eea07f.jpg: 384x640 3 license-plates, 4 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train710\u001b[0m\n",
            "\n",
            "image 1/1 /content/bdd100knewsmall/images/test/54a92bc0-c547f811.jpg: 384x640 4 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/train711\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/runs.zip /content/runs\n"
      ],
      "metadata": {
        "id": "jBG3EGEtryVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a20015-8c77-40d9-ec2d-b6289324f1e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/detect/ (stored 0%)\n",
            "  adding: content/runs/detect/train75/ (stored 0%)\n",
            "  adding: content/runs/detect/train75/661e9976-788d0b85.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train76/ (stored 0%)\n",
            "  adding: content/runs/detect/train76/760e39d9-abd0917b.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train73/ (stored 0%)\n",
            "  adding: content/runs/detect/train73/66bf95f9-d8d18d04.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train77/ (stored 0%)\n",
            "  adding: content/runs/detect/train77/616411ef-87a1fdaf.jpg (deflated 11%)\n",
            "  adding: content/runs/detect/train714/ (stored 0%)\n",
            "  adding: content/runs/detect/train714/bd12ea92bcab1afd_jpg.rf.fe51aa4c3da615ae6656ea88fc7250e3.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/train74/ (stored 0%)\n",
            "  adding: content/runs/detect/train74/10a103b3-3a42fe0a.jpg (deflated 12%)\n",
            "  adding: content/runs/detect/train/ (stored 0%)\n",
            "  adding: content/runs/detect/train/confusion_matrix.png (deflated 18%)\n",
            "  adding: content/runs/detect/train/results.csv (deflated 83%)\n",
            "  adding: content/runs/detect/train/results.png (deflated 7%)\n",
            "  adding: content/runs/detect/train/train_batch13131.jpg (deflated 14%)\n",
            "  adding: content/runs/detect/train/F1_curve.png (deflated 7%)\n",
            "  adding: content/runs/detect/train/R_curve.png (deflated 7%)\n",
            "  adding: content/runs/detect/train/labels_correlogram.jpg (deflated 27%)\n",
            "  adding: content/runs/detect/train/PR_curve.png (deflated 6%)\n",
            "  adding: content/runs/detect/train/val_batch2_labels.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/events.out.tfevents.1712843402.11bc37421953.3868.0 (deflated 92%)\n",
            "  adding: content/runs/detect/train/train_batch0.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train/train_batch13132.jpg (deflated 13%)\n",
            "  adding: content/runs/detect/train/train_batch13130.jpg (deflated 13%)\n",
            "  adding: content/runs/detect/train/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/args.yaml (deflated 52%)\n",
            "  adding: content/runs/detect/train/val_batch1_pred.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/P_curve.png (deflated 6%)\n",
            "  adding: content/runs/detect/train/val_batch0_pred.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train/labels.jpg (deflated 31%)\n",
            "  adding: content/runs/detect/train/val_batch2_pred.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train/confusion_matrix_normalized.png (deflated 20%)\n",
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train/train_batch1.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train/train_batch2.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train716/ (stored 0%)\n",
            "  adding: content/runs/detect/train716/d2fe2b47668e9d8e_jpg.rf.c3c019d146ec1fc0bcf7fbeb12c7bc7f.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train72/ (stored 0%)\n",
            "  adding: content/runs/detect/train72/27764b50-4df2e277.jpg (deflated 12%)\n",
            "  adding: content/runs/detect/train8/ (stored 0%)\n",
            "  adding: content/runs/detect/train8/ce97f7bc90e97109_jpg.rf.0ee971ca2acc7c8826290a5a80153777.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/train11/ (stored 0%)\n",
            "  adding: content/runs/detect/train11/c1d8b110186e095a_jpg.rf.1515701021c709417f9e92537a1d3714.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/train3/ (stored 0%)\n",
            "  adding: content/runs/detect/train3/5ea1f2ff-b711934b.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train6/ (stored 0%)\n",
            "  adding: content/runs/detect/train6/70aee1aa-2792525a.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train12/ (stored 0%)\n",
            "  adding: content/runs/detect/train12/b6e55f97085c3732_jpg.rf.09a6d8dc1a08e66131bdb8b57377b05b.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/train9/ (stored 0%)\n",
            "  adding: content/runs/detect/train9/b8a3f2ea385e45b3_jpg.rf.1b19b61606bd9199fa0f774c35cf8986.jpg (deflated 2%)\n",
            "  adding: content/runs/detect/train713/ (stored 0%)\n",
            "  adding: content/runs/detect/train713/c1d8b110186e095a_jpg.rf.1515701021c709417f9e92537a1d3714.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/train5/ (stored 0%)\n",
            "  adding: content/runs/detect/train5/6adb1b8c-ea1e8e8d.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train715/ (stored 0%)\n",
            "  adding: content/runs/detect/train715/b94993a2d67b455e_jpg.rf.62712d980344cb842644f82e63b13092.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train4/ (stored 0%)\n",
            "  adding: content/runs/detect/train4/02a46296-f95ec53f.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train7/ (stored 0%)\n",
            "  adding: content/runs/detect/train7/confusion_matrix.png (deflated 27%)\n",
            "  adding: content/runs/detect/train7/results.csv (deflated 82%)\n",
            "  adding: content/runs/detect/train7/results.png (deflated 7%)\n",
            "  adding: content/runs/detect/train7/F1_curve.png (deflated 13%)\n",
            "  adding: content/runs/detect/train7/R_curve.png (deflated 13%)\n",
            "  adding: content/runs/detect/train7/labels_correlogram.jpg (deflated 42%)\n",
            "  adding: content/runs/detect/train7/PR_curve.png (deflated 17%)\n",
            "  adding: content/runs/detect/train7/val_batch2_labels.jpg (deflated 13%)\n",
            "  adding: content/runs/detect/train7/val_batch0_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train7/train_batch0.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train7/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train7/events.out.tfevents.1712849648.11bc37421953.3868.1 (deflated 93%)\n",
            "  adding: content/runs/detect/train7/args.yaml (deflated 53%)\n",
            "  adding: content/runs/detect/train7/val_batch1_pred.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train7/P_curve.png (deflated 13%)\n",
            "  adding: content/runs/detect/train7/val_batch0_pred.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train7/labels.jpg (deflated 27%)\n",
            "  adding: content/runs/detect/train7/val_batch2_pred.jpg (deflated 12%)\n",
            "  adding: content/runs/detect/train7/confusion_matrix_normalized.png (deflated 25%)\n",
            "  adding: content/runs/detect/train7/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train7/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train7/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train7/train_batch1.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train7/train_batch2.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train712/ (stored 0%)\n",
            "  adding: content/runs/detect/train712/be9fd0014b5a4f2a_jpg.rf.20dc7369d0a83ad74a123727228dce11.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train2/ (stored 0%)\n",
            "  adding: content/runs/detect/train2/4c7c4eb3-45253918.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train710/ (stored 0%)\n",
            "  adding: content/runs/detect/train710/96d11b79-74eea07f.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train711/ (stored 0%)\n",
            "  adding: content/runs/detect/train711/54a92bc0-c547f811.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train10/ (stored 0%)\n",
            "  adding: content/runs/detect/train10/be654a7eabe0e891_jpg.rf.5e43d4106641423a278d096d24822902.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train79/ (stored 0%)\n",
            "  adding: content/runs/detect/train79/4fba20ab-342281d6.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train78/ (stored 0%)\n",
            "  adding: content/runs/detect/train78/38221668-69780e2f.jpg (deflated 13%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/runs.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9PEWTNkw0HsP",
        "outputId": "1accc6b5-eda3-40f6-c401-ebb3fbc2b922"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_67869574-e3a0-4622-b248-4d393078d427\", \"runs.zip\", 207377922)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}